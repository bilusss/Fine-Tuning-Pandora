# ğŸ”§ Poprawki dla RTX 5070 Ti 16GB - Fine-Tuning Mistral-7B

## âŒ Problem
Kod wychodziÅ‚ z bÅ‚Ä™dem **Out of Memory** po ~361 krokach (29% treningu).

## âœ… RozwiÄ…zanie

### GÅ‚Ã³wne zmiany w `run.py`:

1. **Batch Size**: 20 â†’ **4**
   - Poprzednio: zbyt duÅ¼y dla 16GB VRAM
   - Teraz: bezpieczny rozmiar

2. **Gradient Accumulation**: 1 â†’ **4**
   - Efektywny batch size: 16 (zamiast 20)
   - Symuluje wiÄ™kszy batch bez dodatkowej pamiÄ™ci

3. **Sequence Length**: 192 â†’ **128**
   - KrÃ³tsze sekwencje = mniej pamiÄ™ci
   - Nadal wystarczajÄ…ce dla analizy osobowoÅ›ci

4. **Dataset**: 25k â†’ **50k** przykÅ‚adÃ³w
   - WiÄ™cej danych dziÄ™ki mniejszemu batch size
   - Lepsza jakoÅ›Ä‡ modelu

5. **WyÅ‚Ä…czone problematyczne funkcje**:
   - âŒ `torch_compile` - powodowaÅ‚o OOM
   - âŒ `group_by_length` - nieprzewidywalne uÅ¼ycie VRAM
   - âŒ `tf32` - powodowaÅ‚o problemy z CUDA Graphs
   - âœ… Zmniejszono `dataloader_num_workers` 8 â†’ 2

## ğŸ“Š Oszacowania

### `run.py` (zalecany):
- **Batch size**: 4, grad_accum: 4 (efektywny: 16)
- **Sequence length**: 128
- **Dataset**: 50k train, 5k validation
- **Czas**: ~15-22h
- **Kroki**: 12,500 GPU steps (3,125 effective steps)

### `run_ultra_safe.py` (backup):
- **Batch size**: 2, grad_accum: 8 (efektywny: 16)
- **Sequence length**: 128
- **Dataset**: 50k train, 5k validation
- **Czas**: ~20-25h
- **Kroki**: 25,000 GPU steps (3,125 effective steps)

## ğŸš€ Jak uruchomiÄ‡

### Metoda 1: BezpoÅ›rednio (zalecana)
```bash
python run.py
```

### Metoda 2: Z monitoringiem i logowaniem
```bash
./run_safe.sh
```

### Metoda 3: Ultra-safe mode (jeÅ›li nadal problemy)
```bash
python run_ultra_safe.py
```

## ğŸ’¡ Monitorowanie

Podczas treningu moÅ¼esz monitorowaÄ‡ VRAM w osobnym terminalu:
```bash
watch -n 1 nvidia-smi
```

## ğŸ¯ Oczekiwane rezultaty

- âœ… **Brak OOM** - zmieÅ›ci siÄ™ w 16GB VRAM (~8-12GB peak)
- âœ… **ZakoÅ„czenie w 36h** - realny czas: 15-22h
- âœ… **Dobra jakoÅ›Ä‡** - 50k przykÅ‚adÃ³w z efektywnym batch=16

## ğŸ“ Checkpointy

Model zapisuje siÄ™ co 1000 krokÃ³w w folderze `./Mistral7b01-qlora-36h/` (lub `ultrasafe` dla drugiej wersji).

Ostatnie 2 checkpointy sÄ… zachowywane (`save_total_limit=2`).

## âš ï¸ W razie problemÃ³w

JeÅ›li nadal wystÄ™pujÄ… problemy z pamiÄ™ciÄ…:

1. UÅ¼yj `run_ultra_safe.py` (batch_size=2)
2. Zmniejsz `TRAIN_SIZE` do 30000
3. Zmniejsz `MAX_SEQ_LENGTH` do 96
4. WyczyÅ›Ä‡ cache przed startem:
   ```python
   import torch
   torch.cuda.empty_cache()
   ```

## ğŸ“ˆ PorÃ³wnanie wydajnoÅ›ci

| Wersja | Batch | Grad Acc | Eff. Batch | VRAM Peak | Czas/krok | Czas caÅ‚k. |
|--------|-------|----------|------------|-----------|-----------|------------|
| Stara  | 20    | 1        | 20         | ~16GB+ âŒ | ~3s       | OOM        |
| Nowa   | 4     | 4        | 16         | ~10GB âœ…  | ~2-3s     | ~15-22h    |
| Ultra  | 2     | 8        | 16         | ~8GB âœ…   | ~3-4s     | ~20-25h    |

---

**Autor poprawek**: GitHub Copilot  
**Data**: 5 listopada 2025  
**Status**: âœ… Gotowe do uÅ¼ycia
