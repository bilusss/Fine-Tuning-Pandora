{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.96,
  "eval_steps": 1000,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 1.9114935398101807,
      "learning_rate": 4.2217484008528785e-05,
      "loss": 2.619,
      "step": 100
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 0.7474429607391357,
      "learning_rate": 8.486140724946695e-05,
      "loss": 1.8583,
      "step": 200
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.0208662748336792,
      "learning_rate": 0.00012750533049040512,
      "loss": 1.8577,
      "step": 300
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 0.7442531585693359,
      "learning_rate": 0.00017014925373134328,
      "loss": 1.7648,
      "step": 400
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.8460880517959595,
      "learning_rate": 0.00019999440058283185,
      "loss": 1.7172,
      "step": 500
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.6363061666488647,
      "learning_rate": 0.00019989487283216995,
      "loss": 1.7153,
      "step": 600
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 0.7544125914573669,
      "learning_rate": 0.00019967105612895528,
      "loss": 1.6915,
      "step": 700
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 0.7227327823638916,
      "learning_rate": 0.00019932322894537376,
      "loss": 1.6841,
      "step": 800
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.8010383248329163,
      "learning_rate": 0.00019885182404714297,
      "loss": 1.6738,
      "step": 900
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.5780568718910217,
      "learning_rate": 0.00019825742795506583,
      "loss": 1.6765,
      "step": 1000
    },
    {
      "epoch": 0.10666666666666667,
      "eval_loss": 1.6292304992675781,
      "eval_runtime": 525.9884,
      "eval_samples_per_second": 28.518,
      "eval_steps_per_second": 7.129,
      "step": 1000
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 0.6805228590965271,
      "learning_rate": 0.00019754078021528318,
      "loss": 1.6703,
      "step": 1100
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.6751384139060974,
      "learning_rate": 0.00019670277247913205,
      "loss": 1.6932,
      "step": 1200
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 0.7382197976112366,
      "learning_rate": 0.00019574444739375543,
      "loss": 1.6677,
      "step": 1300
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 0.6355115175247192,
      "learning_rate": 0.00019466699730484325,
      "loss": 1.6708,
      "step": 1400
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7306873798370361,
      "learning_rate": 0.00019347176277311883,
      "loss": 1.6511,
      "step": 1500
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 0.6981043815612793,
      "learning_rate": 0.0001921602309064165,
      "loss": 1.6447,
      "step": 1600
    },
    {
      "epoch": 0.18133333333333335,
      "grad_norm": 0.8345264196395874,
      "learning_rate": 0.0001907340335094259,
      "loss": 1.668,
      "step": 1700
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.5730288028717041,
      "learning_rate": 0.00018919494505340443,
      "loss": 1.6559,
      "step": 1800
    },
    {
      "epoch": 0.20266666666666666,
      "grad_norm": 0.8307514786720276,
      "learning_rate": 0.00018754488046838463,
      "loss": 1.6362,
      "step": 1900
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.7974523901939392,
      "learning_rate": 0.00018578589276062305,
      "loss": 1.6453,
      "step": 2000
    },
    {
      "epoch": 0.21333333333333335,
      "eval_loss": 1.618179202079773,
      "eval_runtime": 526.3774,
      "eval_samples_per_second": 28.497,
      "eval_steps_per_second": 7.124,
      "step": 2000
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.8290050029754639,
      "learning_rate": 0.00018392017045825476,
      "loss": 1.6584,
      "step": 2100
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 0.993169367313385,
      "learning_rate": 0.0001819500348883324,
      "loss": 1.674,
      "step": 2200
    },
    {
      "epoch": 0.24533333333333332,
      "grad_norm": 0.7905612587928772,
      "learning_rate": 0.00017987793728863651,
      "loss": 1.6822,
      "step": 2300
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.7458291053771973,
      "learning_rate": 0.0001777286537532935,
      "loss": 1.6857,
      "step": 2400
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.9083900451660156,
      "learning_rate": 0.00017546144309362447,
      "loss": 1.6574,
      "step": 2500
    },
    {
      "epoch": 0.2773333333333333,
      "grad_norm": 0.7420785427093506,
      "learning_rate": 0.00017310034349396963,
      "loss": 1.6635,
      "step": 2600
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.6691382527351379,
      "learning_rate": 0.00017064829262858385,
      "loss": 1.6479,
      "step": 2700
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 0.8574596643447876,
      "learning_rate": 0.0001681083413330609,
      "loss": 1.6523,
      "step": 2800
    },
    {
      "epoch": 0.30933333333333335,
      "grad_norm": 0.9998810887336731,
      "learning_rate": 0.00016548364980849113,
      "loss": 1.6339,
      "step": 2900
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8807423710823059,
      "learning_rate": 0.00016277748368954752,
      "loss": 1.6572,
      "step": 3000
    },
    {
      "epoch": 0.32,
      "eval_loss": 1.6045942306518555,
      "eval_runtime": 526.482,
      "eval_samples_per_second": 28.491,
      "eval_steps_per_second": 7.123,
      "step": 3000
    },
    {
      "epoch": 0.33066666666666666,
      "grad_norm": 0.7461273670196533,
      "learning_rate": 0.00015999320998139074,
      "loss": 1.6672,
      "step": 3100
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 0.8859564065933228,
      "learning_rate": 0.00015713429287044997,
      "loss": 1.6434,
      "step": 3200
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.7086063623428345,
      "learning_rate": 0.00015420428941429065,
      "loss": 1.6556,
      "step": 3300
    },
    {
      "epoch": 0.3626666666666667,
      "grad_norm": 0.9155349731445312,
      "learning_rate": 0.0001512371412128424,
      "loss": 1.6516,
      "step": 3400
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.7610282897949219,
      "learning_rate": 0.0001481766038745554,
      "loss": 1.6448,
      "step": 3500
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.8301920890808105,
      "learning_rate": 0.00014505612532543993,
      "loss": 1.6549,
      "step": 3600
    },
    {
      "epoch": 0.39466666666666667,
      "grad_norm": 0.64952152967453,
      "learning_rate": 0.0001418795880571528,
      "loss": 1.6678,
      "step": 3700
    },
    {
      "epoch": 0.4053333333333333,
      "grad_norm": 0.9077559113502502,
      "learning_rate": 0.00013865094430946996,
      "loss": 1.6317,
      "step": 3800
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.0410902500152588,
      "learning_rate": 0.00013537421115291954,
      "loss": 1.6463,
      "step": 3900
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.7135984301567078,
      "learning_rate": 0.0001320534654907527,
      "loss": 1.6472,
      "step": 4000
    },
    {
      "epoch": 0.4266666666666667,
      "eval_loss": 1.5939291715621948,
      "eval_runtime": 526.5925,
      "eval_samples_per_second": 28.485,
      "eval_steps_per_second": 7.121,
      "step": 4000
    },
    {
      "epoch": 0.43733333333333335,
      "grad_norm": 0.9363782405853271,
      "learning_rate": 0.0001286928389864707,
      "loss": 1.6419,
      "step": 4100
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.8697912693023682,
      "learning_rate": 0.00012529651292321947,
      "loss": 1.6629,
      "step": 4200
    },
    {
      "epoch": 0.45866666666666667,
      "grad_norm": 0.9015941619873047,
      "learning_rate": 0.00012186871300144754,
      "loss": 1.6292,
      "step": 4300
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 0.8394638299942017,
      "learning_rate": 0.00011841370408129994,
      "loss": 1.6486,
      "step": 4400
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.757217288017273,
      "learning_rate": 0.0001149357848762899,
      "loss": 1.6385,
      "step": 4500
    },
    {
      "epoch": 0.49066666666666664,
      "grad_norm": 0.7531548738479614,
      "learning_rate": 0.00011143928260485013,
      "loss": 1.6444,
      "step": 4600
    },
    {
      "epoch": 0.5013333333333333,
      "grad_norm": 0.8809035420417786,
      "learning_rate": 0.00010792854760641846,
      "loss": 1.6196,
      "step": 4700
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.746803343296051,
      "learning_rate": 0.0001044079479287562,
      "loss": 1.6532,
      "step": 4800
    },
    {
      "epoch": 0.5226666666666666,
      "grad_norm": 0.763299286365509,
      "learning_rate": 0.00010088186389323417,
      "loss": 1.6271,
      "step": 4900
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.7533882260322571,
      "learning_rate": 9.735468264484746e-05,
      "loss": 1.646,
      "step": 5000
    },
    {
      "epoch": 0.5333333333333333,
      "eval_loss": 1.5854263305664062,
      "eval_runtime": 526.1089,
      "eval_samples_per_second": 28.511,
      "eval_steps_per_second": 7.128,
      "step": 5000
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.7561900615692139,
      "learning_rate": 9.383079269374081e-05,
      "loss": 1.6478,
      "step": 5100
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 1.0235974788665771,
      "learning_rate": 9.031457845503493e-05,
      "loss": 1.6177,
      "step": 5200
    },
    {
      "epoch": 0.5653333333333334,
      "grad_norm": 0.7932775020599365,
      "learning_rate": 8.681041479374841e-05,
      "loss": 1.6345,
      "step": 5300
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.7325393557548523,
      "learning_rate": 8.332266158160119e-05,
      "loss": 1.6093,
      "step": 5400
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.7952661514282227,
      "learning_rate": 7.985565827247325e-05,
      "loss": 1.6039,
      "step": 5500
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 0.6774603128433228,
      "learning_rate": 7.64137185032668e-05,
      "loss": 1.6504,
      "step": 5600
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.7445113658905029,
      "learning_rate": 7.300112472688991e-05,
      "loss": 1.609,
      "step": 5700
    },
    {
      "epoch": 0.6186666666666667,
      "grad_norm": 0.6928009390830994,
      "learning_rate": 6.962212288403935e-05,
      "loss": 1.6212,
      "step": 5800
    },
    {
      "epoch": 0.6293333333333333,
      "grad_norm": 0.938626229763031,
      "learning_rate": 6.628091712041165e-05,
      "loss": 1.6479,
      "step": 5900
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.0302144289016724,
      "learning_rate": 6.298166455591545e-05,
      "loss": 1.6178,
      "step": 6000
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.5783121585845947,
      "eval_runtime": 526.3983,
      "eval_samples_per_second": 28.496,
      "eval_steps_per_second": 7.124,
      "step": 6000
    },
    {
      "epoch": 0.6506666666666666,
      "grad_norm": 0.8554088473320007,
      "learning_rate": 5.972847011239331e-05,
      "loss": 1.6318,
      "step": 6100
    },
    {
      "epoch": 0.6613333333333333,
      "grad_norm": 0.6743997931480408,
      "learning_rate": 5.6525381406288136e-05,
      "loss": 1.611,
      "step": 6200
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.8812398910522461,
      "learning_rate": 5.3376383712608845e-05,
      "loss": 1.6398,
      "step": 6300
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 0.8575025796890259,
      "learning_rate": 5.028539500646107e-05,
      "loss": 1.6422,
      "step": 6400
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.6943626999855042,
      "learning_rate": 4.7256261088312316e-05,
      "loss": 1.6037,
      "step": 6500
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.7657038569450378,
      "learning_rate": 4.429275079905657e-05,
      "loss": 1.6165,
      "step": 6600
    },
    {
      "epoch": 0.7146666666666667,
      "grad_norm": 0.7287298440933228,
      "learning_rate": 4.139855133083181e-05,
      "loss": 1.6196,
      "step": 6700
    },
    {
      "epoch": 0.7253333333333334,
      "grad_norm": 0.7383615970611572,
      "learning_rate": 3.857726363942471e-05,
      "loss": 1.607,
      "step": 6800
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.7564302086830139,
      "learning_rate": 3.583239796397038e-05,
      "loss": 1.6189,
      "step": 6900
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.6819816827774048,
      "learning_rate": 3.316736945952163e-05,
      "loss": 1.6238,
      "step": 7000
    },
    {
      "epoch": 0.7466666666666667,
      "eval_loss": 1.5726009607315063,
      "eval_runtime": 526.6604,
      "eval_samples_per_second": 28.481,
      "eval_steps_per_second": 7.12,
      "step": 7000
    },
    {
      "epoch": 0.7573333333333333,
      "grad_norm": 0.6690540909767151,
      "learning_rate": 3.0585493947921505e-05,
      "loss": 1.6329,
      "step": 7100
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.823151707649231,
      "learning_rate": 2.808998379226592e-05,
      "loss": 1.6351,
      "step": 7200
    },
    {
      "epoch": 0.7786666666666666,
      "grad_norm": 0.8667628765106201,
      "learning_rate": 2.5683943900089503e-05,
      "loss": 1.662,
      "step": 7300
    },
    {
      "epoch": 0.7893333333333333,
      "grad_norm": 0.8128980398178101,
      "learning_rate": 2.3370367860247456e-05,
      "loss": 1.635,
      "step": 7400
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.8852593302726746,
      "learning_rate": 2.1173835447572344e-05,
      "loss": 1.6106,
      "step": 7500
    },
    {
      "epoch": 0.8106666666666666,
      "grad_norm": 0.9127934575080872,
      "learning_rate": 1.905270983751656e-05,
      "loss": 1.6165,
      "step": 7600
    },
    {
      "epoch": 0.8213333333333334,
      "grad_norm": 0.6886307001113892,
      "learning_rate": 1.703229864473811e-05,
      "loss": 1.6322,
      "step": 7700
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.6725929975509644,
      "learning_rate": 1.5115115659822577e-05,
      "loss": 1.6142,
      "step": 7800
    },
    {
      "epoch": 0.8426666666666667,
      "grad_norm": 0.7192400097846985,
      "learning_rate": 1.330354623707587e-05,
      "loss": 1.6013,
      "step": 7900
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.7087221145629883,
      "learning_rate": 1.1599844326672272e-05,
      "loss": 1.6039,
      "step": 8000
    },
    {
      "epoch": 0.8533333333333334,
      "eval_loss": 1.5686373710632324,
      "eval_runtime": 530.7488,
      "eval_samples_per_second": 28.262,
      "eval_steps_per_second": 7.065,
      "step": 8000
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.8131902813911438,
      "learning_rate": 1.0006129670295216e-05,
      "loss": 1.619,
      "step": 8100
    },
    {
      "epoch": 0.8746666666666667,
      "grad_norm": 0.6892266869544983,
      "learning_rate": 8.52438516376004e-06,
      "loss": 1.647,
      "step": 8200
    },
    {
      "epoch": 0.8853333333333333,
      "grad_norm": 0.7354729771614075,
      "learning_rate": 7.156454389899803e-06,
      "loss": 1.6404,
      "step": 8300
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.8356577157974243,
      "learning_rate": 5.904039324784261e-06,
      "loss": 1.6171,
      "step": 8400
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.7062135338783264,
      "learning_rate": 4.768698220125345e-06,
      "loss": 1.6409,
      "step": 8500
    },
    {
      "epoch": 0.9173333333333333,
      "grad_norm": 0.7092110514640808,
      "learning_rate": 3.7518436645042953e-06,
      "loss": 1.6264,
      "step": 8600
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.9171832203865051,
      "learning_rate": 2.8547408258324802e-06,
      "loss": 1.61,
      "step": 8700
    },
    {
      "epoch": 0.9386666666666666,
      "grad_norm": 0.7174862027168274,
      "learning_rate": 2.078505877232584e-06,
      "loss": 1.6369,
      "step": 8800
    },
    {
      "epoch": 0.9493333333333334,
      "grad_norm": 0.7155582904815674,
      "learning_rate": 1.4300427446230725e-06,
      "loss": 1.6122,
      "step": 8900
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6885465979576111,
      "learning_rate": 8.970593509454617e-07,
      "loss": 1.6352,
      "step": 9000
    },
    {
      "epoch": 0.96,
      "eval_loss": 1.567502737045288,
      "eval_runtime": 526.4167,
      "eval_samples_per_second": 28.495,
      "eval_steps_per_second": 7.124,
      "step": 9000
    }
  ],
  "logging_steps": 100,
  "max_steps": 9375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.8728785498402e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
